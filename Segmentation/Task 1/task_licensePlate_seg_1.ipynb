{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Fwz0YpTI3X",
        "outputId": "c8496c2d-9dfb-4ad9-a1ea-61915a11f79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "License Plate Segmentation"
      ],
      "metadata": {
        "id": "JBwDfnTxaPbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create virtual ennv\n",
        "!apt-get install -y python3-venv"
      ],
      "metadata": {
        "id": "0uh6ovjTSojb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m venv task1\n",
        "!task1/bin/activate.bat"
      ],
      "metadata": {
        "id": "gk4E1CpRTyv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Task_LicensePlateSeg/datasets/licenseplate_80_10_10.zip"
      ],
      "metadata": {
        "id": "HgBgRZW9oZs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "# to load the dataset\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "vLc_WdaBE-uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MOBILENET BACKBONE\n",
        "# model = torchvision.models.segmentation.deeplabv3_mobilenet_v3_large(pretrained=True)\n",
        "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large,DeepLabV3_MobileNet_V3_Large_Weights\n",
        "weights = DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT\n",
        "model = deeplabv3_mobilenet_v3_large(weights)"
      ],
      "metadata": {
        "id": "nn_6W9NEFKSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a2d28f-2173-4648-cce0-f493581f1810"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESNET 50 BACKBONE\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50,DeepLabV3_ResNet50_Weights\n",
        "weights = DeepLabV3_ResNet50_Weights.DEFAULT\n",
        "model = deeplabv3_resnet50(weights)"
      ],
      "metadata": {
        "id": "PR3vJv83U08E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2635cd64-788b-43bc-9e68-af844c171c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n",
            "100%|██████████| 161M/161M [00:02<00:00, 73.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2  # Set the number of classes : plate and background\n",
        "batch_size = 8\n",
        "epochs = 100\n",
        "data_dir = '/content/licenseplate_80_10_10' #apth to the dataset\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # lower the learning rate\n",
        "\n",
        "transform = weights.transforms(resize_size=None)\n",
        "\n",
        "# change the classifier at the end of the model\n",
        "model.classifier[-1] = torch.nn.Conv2d(256, num_classes, kernel_size=(1, 1))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "pGoe7JBWFKdn"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "k9ZEOlATNouw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class LicensePlateDataset(Dataset):\n",
        "  def __init__(self,root_dir,phase,transformer=None):\n",
        "    self.root_dir = os.path.join(data_dir, phase)\n",
        "    print(self.root_dir)\n",
        "    self.image_dir = os.path.join(self.root_dir, 'Images')\n",
        "    self.mask_dir = os.path.join(self.root_dir, 'SegmentationClass')\n",
        "    self.image_filenames = os.listdir(self.image_dir)\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_filenames)\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_path = os.path.join(self.image_dir, self.image_filenames[index])\n",
        "    mask_path = os.path.join(self.mask_dir, self.image_filenames[index])\n",
        "    # print(mask_path,image_path)\n",
        "    \n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    target = Image.open(mask_path).convert('RGB')\n",
        "\n",
        "    transform_resize = torchvision.transforms.Resize((220,400))\n",
        "    resized_image,resized_target = transform_resize(image), transform_resize(target)\n",
        "    \n",
        "    # Apply any preprocessing\n",
        "    if self.transformer is not None:\n",
        "        resized_image = self.transformer(resized_image)\n",
        "        resized_target = torchvision.transforms.ToTensor()(resized_target)\n",
        "    \n",
        "    return resized_image, resized_target\n",
        "\n",
        "train_dataset = LicensePlateDataset(data_dir,phase='train',transformer=transform)\n",
        "val_dataset = LicensePlateDataset(data_dir,phase='val',transformer=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "dataLoader = {'train':train_loader, 'val':val_loader}"
      ],
      "metadata": {
        "id": "EXQsr7Q1-JsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037e152f-acb6-4fed-f7f1-4a05af8fc56f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/licenseplate_80_10_10/train\n",
            "/content/licenseplate_80_10_10/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,epochs,optimizer,loss_fn,dataLoader,device):\n",
        "  import copy\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = 10.0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      val_loss = 0.0\n",
        "      train_loss = 0.0\n",
        "\n",
        "      print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
        "      \n",
        "      # Training phase \n",
        "      model.train()\n",
        "      for images, targets in dataLoader['train']:\n",
        "          images = images.to(device)\n",
        "          targets = targets.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          \n",
        "          pred = model(images)['out']\n",
        "          loss = loss_fn(pred, torch.argmax(targets, dim=1)) # get a single channel from the mask\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss += loss.item() * images.size(0) # multiplied by batch_size\n",
        "      \n",
        "      train_loss /= len(dataLoader['train'].dataset)\n",
        "      print('Training Loss: {:.4f}'.format(train_loss))\n",
        "      \n",
        "      # Validation every 10 epochs\n",
        "      if (epoch+1) % 10 == 0:\n",
        "        print(\"-----------------------------\")\n",
        "        model.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          for images, targets in dataLoader['val']:\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            pred = model(images)['out']\n",
        "            loss = loss_fn(pred, torch.argmax(targets, dim=1)) # get a single channel from the mask\n",
        "\n",
        "            val_loss += loss.item() * images.size(0) # multiplied by batch_size\n",
        "\n",
        "        val_loss /= len( dataLoader['val'].dataset)\n",
        "          \n",
        "        print('Validation Loss: {:.4f}'.format(val_loss))\n",
        "        \n",
        "        if best_loss*10000 > val_loss*10000:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            \n",
        "      print('-' * 10)\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  return model,best_loss\n",
        "\n",
        "\n",
        "model,best_loss = train(model,epochs,optimizer,loss_fn,dataLoader,device)"
      ],
      "metadata": {
        "id": "U_LbwjHc85fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss"
      ],
      "metadata": {
        "id": "UA46ZYQuZ3AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,f='/content/drive/MyDrive/Task_LicensePlateSeg/results/model_80_10_10/deeplabv3_mobilenet_v3_large/model_80_10_10')"
      ],
      "metadata": {
        "id": "vxWIw9RsFLlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,f='/content/drive/MyDrive/Task_LicensePlateSeg/results/model_80_10_10/deeplabv3_resnet50/model_80_10_10')"
      ],
      "metadata": {
        "id": "Dd-9j_Oyumj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Metrics\n",
        "1. IOU for all test images\n",
        "2. mAP"
      ],
      "metadata": {
        "id": "lMUhNheZ44SB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "9NgX7-VqzGmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perfomance metric for test  --- mAP and IOU\n",
        "\n",
        "def compute_IOU(model, test_loader,device,num_classes):\n",
        "    from torchmetrics import JaccardIndex\n",
        "    import numpy as np\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    jaccard = JaccardIndex(task=\"multiclass\", num_classes=num_classes)\n",
        "    jaccard = jaccard.to(device)\n",
        "\n",
        "    IOU = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for images, masks in test_loader:\n",
        "          images = images.to(device)\n",
        "          targets = masks.to(device)\n",
        "          one_channel_masks =torch.argmax(targets, dim=1)\n",
        "    \n",
        "          outputs = model(images)['out']\n",
        "          predictions = torch.argmax(outputs, dim=1)\n",
        "          # print(predictions.shape,one_channel_masks.shape)\n",
        "          iou = jaccard(predictions, one_channel_masks)\n",
        "          iou = iou.detach().cpu().numpy()\n",
        "          IOU.append(iou)\n",
        "          # print(iou)\n",
        "\n",
        "    mean_iou = np.mean(IOU)\n",
        "    return mean_iou,IOU\n",
        "\n",
        "\n",
        "test_dataset = LicensePlateDataset(data_dir,phase='test',transformer=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8)\n",
        "\n",
        "mean_iou,iou_list = compute_IOU(model,test_loader,device,2)\n",
        "print(\"mean IOU---- \",mean_iou)"
      ],
      "metadata": {
        "id": "G-WTYiJ6zre5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Prepare the test images folder\n",
        "test_folder = '/content/licenseplate_80_10_10/test/Images'\n",
        "\n",
        "test_batch = torch.zeros( (10,3,220,400), dtype=torch.float32)\n",
        "\n",
        "# Iterate over the test images\n",
        "for i,image_file in enumerate(os.listdir(test_folder)):\n",
        "    # Load and preprocess the image\n",
        "    image_path = os.path.join(test_folder, image_file)\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    image_tensor = transform(image)\n",
        "    test_batch[i]=image_tensor\n",
        "    image_tensor=image_tensor.unsqueeze(0).to(device)\n",
        "    # print(image_tensor.shape)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)['out']\n",
        "        predicted_masks = torch.argmax(outputs.softmax(dim=1), dim=1)\n",
        "\n",
        "    # Convert predicted masks to numpy arrays for visualization\n",
        "    predicted_masks = predicted_masks.squeeze().cpu().numpy()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(predicted_masks,alpha=0.6)\n",
        "    plt.title(\"pred\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "    # plt.savefig('/content/drive/MyDrive/Task_LicensePlateSeg/results/model_80_10_10/deeplabv3_mobilenet_v3_large/pred'+str(i)+'.png')"
      ],
      "metadata": {
        "id": "iLkB_Tt-mZLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch= test_batch.to(device)\n",
        "\n",
        "repetitions=10\n",
        "total_time = 0\n",
        "with torch.no_grad():\n",
        "    for rep in range(repetitions):\n",
        "        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "        starter.record()\n",
        "        _ = model(test_batch)\n",
        "        ender.record()\n",
        "        torch.cuda.synchronize() # wait til the gpu completes\n",
        "        curr_time = starter.elapsed_time(ender)/1000 #convert to second\n",
        "        total_time += curr_time\n",
        "Throughput =   (repetitions*test_batch.size()[0])/total_time\n",
        "print('Final Throughput: ',Throughput)\n",
        "print('Inference Time: ',total_time/(repetitions*test_batch.size()[0]))"
      ],
      "metadata": {
        "id": "bUivGJbPSULE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kiiPwPuWl5aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xmoRsdnkX3nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMRxpU2hX9Op"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}